{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5c250f",
   "metadata": {},
   "source": [
    "1. En este paso, el banco nos envía la carta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a39d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjunto guardado: 8301225661_20250716_NDFV_FW261505.pdf\n",
      "Adjunto guardado: 8301225661_20250724_NDFC_FW261945.pdf\n",
      "Adjunto guardado: 1307699.pdf\n",
      "Adjunto guardado: 1305459.pdf\n",
      "Adjunto guardado: 8301225661_20250716_NDFV_FW261505.pdf\n",
      "Adjunto guardado: 8301225661_20250724_NDFC_FW261945.pdf\n",
      "Adjunto guardado: 1304173.pdf\n",
      "Adjunto guardado: 1304176.pdf\n",
      "Adjunto guardado: 8301225661_20250724_NDFC_FW261945.pdf\n",
      "Adjunto guardado: 1305459.pdf\n",
      "Adjunto guardado: 1305459.pdf\n",
      "Adjunto guardado: 8301225661_20250716_NDFV_FW261505.pdf\n",
      "Adjunto guardado: 8301225661_20250716_NDFV_FW261505.pdf\n",
      "Adjunto guardado: 1304173.pdf\n",
      "Adjunto guardado: 1304176.pdf\n",
      "Adjunto guardado: 8301225661_20250716_NDFV_FW261505.pdf\n",
      "Adjunto guardado: Bancol 12345.pdf\n",
      "Adjunto guardado: Bancol 123456.pdf\n",
      "Adjunto guardado: 1296252.pdf\n",
      "Adjunto guardado: 1296252.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058688986.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058689081.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058689445.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058688995.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058689095.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058687675.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058687902.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058689521.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058688670.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058684752.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058689301.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058688060.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025073058686196.pdf\n",
      "Código ingresado correctamente.\n",
      "Descarga iniciada correctamente.\n",
      "Archivo movido: Confirmation-AE2025071091434370.pdf\n"
     ]
    }
   ],
   "source": [
    "import win32com.client\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Fecha actual\n",
    "today = datetime.now()\n",
    "year = today.strftime(\"%Y\")\n",
    "month = today.strftime(\"%m\")\n",
    "day = today.strftime(\"%d%m%y\")\n",
    "\n",
    "# Crear carpeta de salida\n",
    "base_dir = Path(r\"Z:\\17. Reporting Automation\\Cartas NDFs\\Cartas sin firmas\")\n",
    "output_dir = base_dir / year / month / day\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Conexión con Outlook\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "inbox = outlook.Folders(\"Mercado de Capitales Colombia\").Folders(\"Cartas NDF\")\n",
    "messages = inbox.Items\n",
    "messages.Sort(\"[ReceivedTime]\", True)\n",
    "\n",
    "# Rango de tiempo: desde el inicio del día hasta ahora\n",
    "#start = datetime(today.year, today.month, today.day)\n",
    "\n",
    "# Acá si necesito procesar todos los correos del mes\n",
    "start = datetime(today.year, today.month, 1)\n",
    "\n",
    "# La fecha si es siempre el día de hoy\n",
    "end = today\n",
    "\n",
    "messages_today = messages.Restrict(\n",
    "    \"[ReceivedTime] >= '\" + start.strftime(\"%m/%d/%Y %I:%M %p\") +\n",
    "    \"' AND [ReceivedTime] < '\" + end.strftime(\"%m/%d/%Y %I:%M %p\") + \"'\"\n",
    ")\n",
    "\n",
    "# Procesar correos con adjuntos\n",
    "if messages_today.Count == 0:\n",
    "    print(\"No hay correos recibidos hoy con adjuntos.\")\n",
    "else:\n",
    "    for message in messages_today:\n",
    "        received = message.ReceivedTime.replace(tzinfo=None)\n",
    "        if start <= received <= end:\n",
    "\n",
    "            attachments = message.Attachments\n",
    "            for attachment in attachments:\n",
    "                filename = attachment.FileName.lower()\n",
    "                if filename.endswith(\".pdf\") or filename.endswith(\".xlsx\"):\n",
    "                    safe_filename = re.sub(r'[^0-9a-zA-ZáéíóúÁÉÍÓÚñÑ\\.\\-_ ]+', '', attachment.FileName)\n",
    "                    attachment.SaveAsFile(output_dir / safe_filename)\n",
    "                    print(f\"Adjunto guardado: {safe_filename}\")\n",
    "\n",
    "# Procesar correos con enlaces de descarga\n",
    "for message in messages_today:\n",
    "    if message.Subject.startswith(\"JPM Confirmation ID\"):\n",
    "        received = message.ReceivedTime.replace(tzinfo=None)\n",
    "        if start <= received <= end:\n",
    "\n",
    "            body = message.Body\n",
    "\n",
    "            # Extraer URL y código de verificación\n",
    "            url_match = re.search(r\"https://[^\\s]+\", body)\n",
    "            code_match = re.search(r\"Verification Code:\\s*([A-Z0-9]+)\", body)\n",
    "\n",
    "            if url_match and code_match:\n",
    "                url = url_match.group(0)\n",
    "                code = code_match.group(1)\n",
    "\n",
    "                # Abrir navegador y automatizar ingreso del código\n",
    "                driver = webdriver.Chrome()\n",
    "                driver.get(url)\n",
    "\n",
    "                time.sleep(3)\n",
    "\n",
    "                try:\n",
    "                    input_box = driver.find_element(By.ID, \"txtAccessCode\")\n",
    "                    input_box.send_keys(code)\n",
    "                    input_box.send_keys(Keys.RETURN)\n",
    "                    print(\"Código ingresado correctamente.\")\n",
    "                    time.sleep(3)\n",
    "\n",
    "                    download_link = driver.find_element(By.CLASS_NAME, \"Q416_downloadspecific\")\n",
    "                    download_link.click()\n",
    "                    print(\"Descarga iniciada correctamente.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Error durante la automatización del navegador:\", e)\n",
    "\n",
    "                time.sleep(2)\n",
    "                driver.quit()\n",
    "\n",
    "                # Mover archivos PDF descargados hoy\n",
    "                downloads_dir = Path(r\"C:\\Users\\ntorreslo\\Downloads\")\n",
    "                for file in downloads_dir.glob(\"Confirmation-AE*.pdf\"):\n",
    "                    if file.is_file():\n",
    "                        modified_time = datetime.fromtimestamp(file.stat().st_mtime)\n",
    "                        if modified_time.date() == today.date():\n",
    "                            destination = output_dir / file.name\n",
    "                            shutil.move(str(file), str(destination))\n",
    "                            print(f\"Archivo movido: {file.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507df64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asunto: JPM Confirmation ID AE2025071091434370—COLOMBIA TELECOMUNICACIONES SA ESP BIC\n",
      "Contenido del correo:\n",
      "AVISO/WARNING: Este correo electrónico se originó desde fuera de la organización. No haga clic en enlaces ni abra archivos adjuntos a menos que reconozca al remitente y sepa que el contenido es seguro / This email has been originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and know the content is safe. \n",
      "\n",
      " \t\n",
      "New Confirmation Pending Review \n",
      "\n",
      "A new confirmation document is ready. Please confirm core economics are correct. \n",
      "\n",
      "To review, click the link—then enter the access code. \n",
      "\n",
      "J.P. Morgan Confirmation <https://jpmorgan.eu9.smartcommunications.cloud/produce/wizard/e023906b-5f2e-47be-9c43-a3a3da21cec5/?workflowId=c4f19701-f94f-897a-bc89-3b39a6cd358a&tu=1> \n",
      "\n",
      "Verification Code: W54G91JSZ3 \n",
      "\n",
      "Questions or issues? Contact: london.fx.confirmations@jpmorgan.com <mailto:london.fx.confirmations@jpmorgan.com> \n",
      "\n",
      "If you are not the intended recipient of this email, please notify the sender and delete this email and any attachments. This email is confidential and subject to important disclaimers and conditions including on offers for the purchase or sale of securities, accuracy and completeness of information, viruses, confidentiality, legal privilege, and legal entity disclaimers, available at http://www.jpmorgan.com/pages/disclosures/email <http://www.jpmorgan.com/pages/disclosures/email> . J.P. Morgan takes reasonable measures to protect the confidentiality of the information sent to you and this will include transmitting emails using TLS encryption. TLS is an industry-standard form of encryption software. To ensure secure transmission by email you must have TLS encryption software installed on your gateways. If you already have TLS encryption software there is no further action required and all e-mails will be received from J.P. Morgan encrypted. If you do not have TLS encryption software on your gateways then you will receive emails in an unencrypted format from J.P. Morgan and therefore your information could be viewed by persons other than the intended recipient in the event of a manual error or electronic interception. If you wish to obtain further information on TLS encryption please contact your usual email software vendor for further advice. \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import win32com.client\n",
    "\n",
    "# Conexión con Outlook\n",
    "outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "\n",
    "# Acceder a la carpeta específica\n",
    "inbox = outlook.Folders(\"Mercado de Capitales Colombia\").Folders(\"Cartas NDF\")\n",
    "\n",
    "# Obtener todos los correos\n",
    "messages = inbox.Items\n",
    "messages.Sort(\"[ReceivedTime]\", True)\n",
    "\n",
    "# Filtrar correos cuyo asunto comienza con \"JPM Confirmation ID\"\n",
    "for message in messages:\n",
    "    if message.Subject.startswith(\"JPM Confirmation ID\"):\n",
    "        print(f\"Asunto: {message.Subject}\")\n",
    "        print(\"Contenido del correo:\")\n",
    "        print(message.Body)\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511f066",
   "metadata": {},
   "source": [
    "2. En el punto anterior ya se guarda el pdf en la carpeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019c10d",
   "metadata": {},
   "source": [
    "3. En el Excel de seguimiento de las cartas, hacer las operaciones necesarias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8862ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path \n",
    "\n",
    "# Configurar la ruta de Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "def extract_data_from_pdf(file_path):\n",
    "    # Open the PDF file\n",
    "    #pdf_document = fitz.open(file_path)\n",
    "    #text = \"\"\n",
    "    # Extract text from each page\n",
    "    #for page_num in range(len(pdf_document)):\n",
    "    #    page = pdf_document.load_page(page_num)\n",
    "    #    text += page.get_text()\n",
    "    images = convert_from_path(file_path\n",
    "                               , dpi = 500\n",
    "                               , poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin')  \n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image, lang='spa')  # Cambia 'spa' por el idioma deseado\n",
    "\n",
    "    # Define regex patterns for both Spanish and English documents\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        \"fecha_celebracion\": r\"(?i)(Fecha de Celebración|Trade Date):\\s*([\\d]{1,2}\\s\\w+\\s\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4})\",\n",
    "        \"fecha_vencimiento\": r\"(?i)(Fecha de Vencimiento|Valuation Date):\\s*([\\d]{1,2}\\s\\w+\\s\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4})\",\n",
    "        \"fecha_liquidacion\": r\"(?i)(Fecha de Liquidación|Settlement Date):\\s*([\\d]{1,2}\\s\\w+\\s\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4})\",\n",
    "        \"tasa_forward\": r\"(?i)(Tasa Forward|Tasa|Forward Rate):\\s*([\\d,\\.]+)\",\n",
    "        \"valor_nominal\": r\"(?i)(Valor Nominal|Notional Amount|Valor Negociado):\\s*USD\\s*([\\d,\\.]+)\",\n",
    "        \"contraparte\": r\"(?i)(Vendedor|Seller|Parte A):\\s*([\\w\\s]+)\",\n",
    "        \"tipo_operacion\": r\"(?i)(Tipo de Operación|Type of Operation):\\s*([\\w\\s]+)\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        \"fecha_celebracion\": r\"(?i)(Fecha de Celebraci[oó]n|Trade Date):?\\s*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4}|\\w+\\s\\d{1,2}\\sdel\\s\\d{4})\",\n",
    "        \"fecha_vencimiento\": r\"(?i)(Fecha de Vencimiento|Fixing Date|Valuation Date|F\\.? VEN):?\\s*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4}|\\w+\\s\\d{1,2}\\sdel\\s\\d{4})\",\n",
    "        \"fecha_liquidacion\": r\"(?i)(Fecha de Liquidaci[oó]n|Fecha de Cumplimiento|Settlement Date|F\\.? CUM|Fecha Compensaci[oó]n):?\\s*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4}|\\w+\\s\\d{1,2}\\sdel\\s\\d{4})\",\n",
    "        \"tasa_forward\": r\"(?i)(Tasa Forward|Forward Rate|Tasa):?\\s*\\$?\\s*([\\d\\.,]+)\",\n",
    "        \"valor_nominal\": r\"(?i)(Valor Nominal|Notional Amount|Valor Negociado| Monto en USD):\\s*USD\\s*([\\d,\\.]+)\",\n",
    "        #\"contraparte\": r\"(?i)(Parte A|Vendedor|Seller|Reference Currency Seller):?\\s*([A-ZÁÉÍÓÚÑa-z\\s\\.\\-]+)\",\n",
    "        \"contraparte\": r\"(?i)(SANTANDER|BANCOLOMBIA|JPMorgan|OCCIDENTE|DAVIVIENDA|BANCO DE BOGOT[AÁ]|CITIBANK|SCOTIABANK)\",\n",
    "        \"tipo_operacion\": r\"(?i)(Tipo de Operación|Type of Operation):\\s*([\\w\\s]+)\"\n",
    "    }\n",
    "      \n",
    "\n",
    "    data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            data[key] = match.group(2).strip() if match.lastindex >= 2 else match.group(1).strip()\n",
    "        else:\n",
    "            data[key] = None\n",
    "\n",
    "    # Clean the forward rate to retain only digits, commas, and periods\n",
    "    if data[\"tasa_forward\"]:\n",
    "        data[\"tasa_forward\"] = re.sub(r\"[^\\d,\\.]\", \"\", data[\"tasa_forward\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_pdfs_in_directory(directory):\n",
    "    records = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            data = extract_data_from_pdf(file_path)\n",
    "            data[\"nombre_archivo\"] = filename\n",
    "            records.append(data)\n",
    "    return records\n",
    "\n",
    "# Directory containing the PDFs\n",
    "directory = r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas sin firmas\"\n",
    "\n",
    "# Process the PDFs and get the data\n",
    "records = process_pdfs_in_directory(directory)\n",
    "\n",
    "# Create a DataFrame and save to Excel\n",
    "df = pd.DataFrame(records)\n",
    "df.to_excel(r\"Z:/17. Reporting Automation/Cartas NDFs/forward_tracking.xlsx\", index=False)\n",
    "\n",
    "print(\"The data has been successfully extracted and saved to forward_tracking.xlsx.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path \n",
    "\n",
    "# Configurar la ruta de Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "def extract_data_from_pdf(file_path):\n",
    "    # Open the PDF file\n",
    "    #pdf_document = fitz.open(file_path)\n",
    "    #text = \"\"\n",
    "    # Extract text from each page\n",
    "    #for page_num in range(len(pdf_document)):\n",
    "    #    page = pdf_document.load_page(page_num)\n",
    "    #    text += page.get_text()\n",
    "    images = convert_from_path(file_path\n",
    "                               , dpi = 500\n",
    "                               , poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin')  \n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image, lang='spa')  # Cambia 'spa' por el idioma deseado\n",
    "\n",
    "    # Define regex patterns for both Spanish and English documents\n",
    "    patterns = {\n",
    "        \"fecha_celebracion\": [\n",
    "    r\"(?:Fecha(?: de Celebraci[oó]n| de Vencimiento| de celebración)?|Trade Date).*?[:\\-]?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4})\",\n",
    "    r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\",\n",
    "    r\"\\b\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4}\\b\",\n",
    "    r\"(?i)(Fecha de Celebraci[oó]n|Trade Date):?\\s*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{4}|\\d{1,2}\\s\\w+\\s\\d{4}|\\w+\\s\\d{1,2}\\sdel\\s\\d{4})\"\n",
    "    ],\n",
    "        \"tasa_forward\": [\n",
    "                   r\"Forward Rate:\\s*([\\d.,]+)\"\n",
    "                 , r\"Tasa Forward\\s*[-:]?\\s*([\\d.,]+)\"\n",
    "                 , r\"Tasa Forward\\s*[-:]?\\s*([\\d.,]+)\"\n",
    "                 , r\"(?i)(Tasa Forward|Forward Rate|Tasa):?\\s*\\$?\\s*([\\d\\.,]+)\"\n",
    "                 , r'(?:Tasa Forward|Forward Rate|Tasa FW).*?[:\\s].*?[\\$\\s]*([\\d,]+\\.?\\d*)'\n",
    "                 , r'(\\d{4}[\\.,]\\d{2})\\s*COP/USD'\n",
    "                 , r'[\\|\\s](\\d{4}[\\.,]\\d{2})[\\|\\s]'\n",
    "                 , r'(\\b\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})\\b)'\n",
    "                 , r\"(?:por encima de)?\\s*\\$?\\s*([\\d]{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2}))\"\n",
    "\n",
    "                 ],\n",
    "        \"valor_nominal\": [\n",
    "    r\"(?:Valor(?: Nocional| Nominal)?|Notional Amount|Monto en USD|Valor Negociado).*?:?\\s*USD\\s*([\\d.,]+)\",\n",
    "    r\"(?i)(Valor Nominal|Notional Amount|Valor Negociado):\\s*USD\\s*([\\d,\\.]+)\",\n",
    "    r\"USD\\s*([\\d.,]+)\",\n",
    "    r\"(?:nocional|nominal|monto|valor)\\s*[:\\-]?\\s*\\$?\\s?\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})?\"\n",
    "    ],\n",
    "        \"contraparte\": [\n",
    "                    r\"JPMorgan, N\\.A\\.\"\n",
    "                  #, r\"SCOTIABANK\\.A\\.\"\n",
    "                  , r'(SCOTIABANK)'\n",
    "                  , r'(DAVIVIENDA)'\n",
    "                  , r'(ITAÚ)'\n",
    "                  , r'(BANCOLOMBIA)'\n",
    "                  , r'(JPMorgan)'\n",
    "                  , r'(BANCO DE OCCIDENTE)'\n",
    "                  , r'(BANCO SANTANDER)'\n",
    "                  #, r'(BANCO SANTANDER[^,]*)'\n",
    "                  , r'(CITIBANK COLOMBIA)'\n",
    "                  ]\n",
    "        \n",
    "    }\n",
    "      \n",
    "\n",
    "    data = {}\n",
    "    for key, pattern_list in patterns.items():\n",
    "        match = None\n",
    "        for pattern in pattern_list:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                if match.lastindex:  # Verifica si hay grupos capturados\n",
    "                    # Usa el último grupo capturado (el más específico)\n",
    "                    data[key] = match.group(match.lastindex).strip()\n",
    "                else:\n",
    "                    data[key] = match.group(0).strip()  # Usa todo el match si no hay grupos\n",
    "                break\n",
    "            if not match:\n",
    "                data[key] = None\n",
    "\n",
    "\n",
    "    # Clean the forward rate to retain only digits, commas, and periods\n",
    "    if data[\"tasa_forward\"]:\n",
    "        data[\"tasa_forward\"] = re.sub(r\"[^\\d,\\.]\", \"\", data[\"tasa_forward\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_pdfs_in_directory(directory, output_directory):\n",
    "    records = []\n",
    "    current_id = 1001\n",
    "    today = pd.Timestamp.today().strftime('%d-%m-%y')\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            data = extract_data_from_pdf(file_path)\n",
    "            data[\"nombre_archivo\"] = filename\n",
    "            data[\"id\"] = current_id\n",
    "            data[\"fecha_proceso\"] = today\n",
    "\n",
    "            contraparte = data.get(\"contraparte\", \"\")\n",
    "            fecha_proceso = data.get(\"fecha_proceso\", today)\n",
    "            nuevo_nombre = f\"{contraparte} {fecha_proceso} {current_id}.pdf\"\n",
    "            data['nuevo_nombre_archivo'] = nuevo_nombre\n",
    "\n",
    "            new_file_path = os.path.join(output_directory, nuevo_nombre)\n",
    "            # Save the PDF with the new name   \n",
    "            os.rename(file_path, new_file_path)\n",
    "\n",
    "\n",
    "            records.append(data)\n",
    "            current_id +=1\n",
    "    return records\n",
    "\n",
    "# Directory containing the PDFs\n",
    "directory = r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas sin firmas\"\n",
    "output_directory = r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas para firmar\"\n",
    "\n",
    "# Process the PDFs and get the data\n",
    "records = process_pdfs_in_directory(directory, output_directory)\n",
    "\n",
    "# Create a DataFrame and save to Excel\n",
    "df = pd.DataFrame(records)\n",
    "df.to_excel(r\"Z:/17. Reporting Automation/Cartas NDFs/forward_tracking_4.xlsx\", index=False)\n",
    "\n",
    "print(\"The data has been successfully extracted and saved to forward_tracking.xlsx.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Configurar la ruta de Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# Patrones de extracción\n",
    "tasa_patterns = [\n",
    "    r\"Forward Rate:\\s*([\\d.,]+)\",\n",
    "    r\"Tasa Forward\\s*[-:]?\\s*([\\d.,]+)\",\n",
    "    r\"(?i)(Tasa Forward|Forward Rate|Tasa):?\\s*\\$?\\s*([\\d\\.,]+)\",\n",
    "    r'(?:Tasa Forward|Forward Rate|Tasa FW).*?[:\\s].*?[\\$\\s]*([\\d,]+\\.?\\d*)',\n",
    "    r'(\\d{4}[\\.,]\\d{2})\\s*COP/USD',\n",
    "    r'[\\|\\s](\\d{4}[\\.,]\\d{2})[\\|\\s]',\n",
    "    r'(\\b\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})\\b)'\n",
    "]\n",
    "\n",
    "valor_patterns = [\n",
    "    r\"(?:Valor(?: Nocional| Nominal)?|Notional Amount|Monto en USD|Valor Negociado).*?:?\\s*USD\\s*([\\d.,]+)\",\n",
    "    r\"USD\\s*([\\d.,]+)\",\n",
    "    r\"(?:nocional|nominal|monto|valor)\\s*[:\\-]?\\s*\\$?\\s?\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})?\"\n",
    "]\n",
    "\n",
    "fecha_patterns = [\n",
    "    r\"(?:Fecha(?: de Celebraci[oó]n| de Vencimiento| de celebración)?|Trade Date).*?[:\\-]?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4})\",\n",
    "    r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\",\n",
    "    r\"\\b\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4}\\b\"\n",
    "]\n",
    "\n",
    "banco_patterns = [\n",
    "    r\"JPMorgan, N\\.A\\.\",\n",
    "    r\"SCOTIABANK\\.A\\.\",\n",
    "    r\"(SCOTIABANK COLPATRIA S\\.A\\.)\",\n",
    "    r\"(DAVIVIENDA)\",\n",
    "    r\"(ITAÚ COLOMBIA S\\.A\\.)\",\n",
    "    r\"(BANCOLOMBIA S\\.A\\.)\",\n",
    "    r\"(JPMorgan)\",\n",
    "    r\"(BANCO DE OCCIDENTE)\",\n",
    "    r\"(BANCO SANTANDER[^,]*)\",\n",
    "    r\"(CITIBANK COLOMBIA)\"\n",
    "]\n",
    "\n",
    "# Función para extraer un campo con múltiples patrones\n",
    "def extract_field(patterns, text, label):\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return f\"{label} no encontrado\"\n",
    "\n",
    "# Función para procesar un archivo PDF y extraer los campos\n",
    "def extract_data_from_pdf(file_path):\n",
    "    images = convert_from_path(file_path, dpi=500, poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin')\n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image, lang='spa')\n",
    "\n",
    "    tasa = extract_field(tasa_patterns, text, \"Tasa Forward\")\n",
    "    valor = extract_field(valor_patterns, text, \"Valor Nominal\")\n",
    "    fecha = extract_field(fecha_patterns, text, \"Fecha de Celebración\")\n",
    "    banco = extract_field(banco_patterns, text, \"Banco\")\n",
    "\n",
    "    return {\n",
    "        \"Tasa Forward\": tasa,\n",
    "        \"Valor Nominal\": valor,\n",
    "        \"Fecha de Celebración\": fecha,\n",
    "        \"Banco\": banco\n",
    "    }\n",
    "\n",
    "# Ruta del directorio con los archivos PDF\n",
    "pdf_directory = r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas sin firmas\"\n",
    "resultados = []\n",
    "\n",
    "# Procesar todos los archivos PDF en el directorio\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.lower().endswith(\".pdf\"):\n",
    "        file_path = os.path.join(pdf_directory, filename)\n",
    "        data = extract_data_from_pdf(file_path)\n",
    "        data[\"Archivo\"] = filename\n",
    "        resultados.append(data)\n",
    "\n",
    "# Crear un DataFrame y exportar a Excel\n",
    "df = pd.DataFrame(resultados)\n",
    "df.to_excel(r\"Z:/17. Reporting Automation/Cartas NDFs/forward_tracking_3.xlsx\", index=False)\n",
    "\n",
    "print(\"Extracción completada. Resultados guardados en 'resultados_extraccion.xlsx'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e403b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import ollama\n",
    "\n",
    "# Ruta del archivo de texto\n",
    "#file_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\texto_extraido_bancolombia.txt\"\n",
    "file_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\texto_extraido_citi.txt\"\n",
    "\n",
    "# Leer el contenido del archivo\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    contrato_texto = f.read()\n",
    "\n",
    "# Construir el prompt\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Eres un experto en análisis de contratos financieros. Extrae ÚNICAMENTE los siguientes campos del texto del contrato de forward:\n",
    "\n",
    "CAMPOS REQUERIDOS:\n",
    "- banco: Nombre completo de la entidad bancaria (buscar en encabezados, firmas, o menciones como \"El Banco\")\n",
    "- tasa_fwd: Tasa forward exacta (formato: usar coma como separador decimal, sin espacios)\n",
    "- valor_nominal_usd: Monto en USD sin formato (solo números y coma decimal, eliminar puntos de miles)\n",
    "- fecha_inicio: Fecha de negociación/formalización de la operación (formato: dd/mm/aaaa)\n",
    "\n",
    "INSTRUCCIONES DE FORMATO:\n",
    "- Responde SOLO con un JSON válido\n",
    "- No incluyas explicaciones, comentarios, ni texto adicional\n",
    "- No uses bloques de código ni etiquetas\n",
    "- Usa comillas dobles para las claves y valores\n",
    "- Si no encuentras un campo, usa null\n",
    "\n",
    "EJEMPLO DE SALIDA ESPERADA:\n",
    "{{\n",
    "  \"banco\": \"BANCOLOMBIA S.A.\",\n",
    "  \"tasa_fwd\": \"4236,20\",\n",
    "  \"valor_nominal_usd\": \"3018127,00\",\n",
    "  \"fecha_inicio\": \"25/09/2024\"\n",
    "}}\n",
    "\n",
    "GUÍAS DE BÚSQUEDA:\n",
    "- banco: Buscar en encabezados, menciones de \"El Banco\", firmas, o entidades que venden/compran\n",
    "- tasa_fwd: Buscar \"Tasa Forward\", \"Forward Rate\", o similar\n",
    "- valor_nominal_usd: Buscar \"Monto en USD\", \"Valor Nominal\", \"Amount\" seguido de cifras\n",
    "- fecha_inicio: Buscar fecha de negociación, formalización, o \"el [fecha] del [año]\"\n",
    "\n",
    "TEXTO DEL CONTRATO:\n",
    "\\\"\\\"\\\"{contrato_texto}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Llamar al modelo Ollama local\n",
    "#respuesta = ollama.chat(model=\"qwen3:0.6b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "respuesta = ollama.chat(model=\"llama3.2:3b\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "print(respuesta['message']['content'])\n",
    "# Convertir la respuesta a diccionario\n",
    "#datos_extraidos = json.loads(respuesta['message']['content'])\n",
    "\n",
    "# Guardar en Excel\n",
    "#df = pd.DataFrame([datos_extraidos])\n",
    "#df.to_excel(\"resultado_forward.xlsx\", index=False)\n",
    "\n",
    "#print(\"Resultado guardado en 'resultado_forward.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from typing import Dict, Optional\n",
    "\n",
    "class ContractExtractor:\n",
    "    def __init__(self, model=\"llama3.2:3b\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: str, method=\"pdfplumber\") -> str:\n",
    "        \"\"\"\n",
    "        Extrae texto de PDF usando diferentes métodos\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if method == \"pdfplumber\":\n",
    "                return self._extract_with_pdfplumber(pdf_path)\n",
    "            elif method == \"pymupdf\":\n",
    "                return self._extract_with_pymupdf(pdf_path)\n",
    "            else:\n",
    "                raise ValueError(\"Método no soportado\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extrayendo texto: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_with_pdfplumber(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extrae texto usando pdfplumber (mejor para tablas)\"\"\"\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "        return text\n",
    "    \n",
    "    def _extract_with_pymupdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extrae texto usando PyMuPDF (más rápido)\"\"\"\n",
    "        text = \"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            text += page.get_text() + \"\\n\"\n",
    "        doc.close()\n",
    "        return text\n",
    "    \n",
    "    def extract_contract_data(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Extrae datos del contrato desde PDF\n",
    "        \"\"\"\n",
    "        # Verificar si el archivo existe\n",
    "        if not Path(pdf_path).exists():\n",
    "            return {\"error\": f\"Archivo no encontrado: {pdf_path}\"}\n",
    "        \n",
    "        # Extraer texto del PDF\n",
    "        print(\"Extrayendo texto del PDF...\")\n",
    "        texto_contrato = self.extract_text_from_pdf(pdf_path)\n",
    "        \n",
    "        if not texto_contrato:\n",
    "            return {\"error\": \"No se pudo extraer texto del PDF\"}\n",
    "        \n",
    "        # Limpiar texto\n",
    "        texto_limpio = self._clean_text(texto_contrato)\n",
    "        \n",
    "        # Crear prompt optimizado\n",
    "        prompt = f\"\"\"\n",
    "Eres un asistente especializado en análisis de contratos financieros.\n",
    "\n",
    "Extrae ÚNICAMENTE estos campos del texto del contrato y responde con JSON limpio:\n",
    "\n",
    "- banco: Nombre completo del banco (buscar en encabezados, firmas, \"El Banco\")\n",
    "- tasa_fwd: Tasa Forward (formato con coma decimal: ej. 4236,20)\n",
    "- valor_nominal_usd: Monto en USD (solo números, sin puntos de miles)\n",
    "- fecha_inicio: Fecha de operación/negociación (formato dd/mm/aaaa)\n",
    "\n",
    "IMPORTANTE: \n",
    "- Para tasa_fwd: Si ves 4.236,20 debe ser 4236,20\n",
    "- Para valor_nominal_usd: Si ves 2,000,000 debe ser 2000000\n",
    "- Responde SOLO con el JSON, sin explicaciones adicionales.\n",
    "\n",
    "Texto del contrato:\n",
    "{texto_limpio[:3000]}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(\"Procesando con Ollama...\")\n",
    "            respuesta = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"repeat_penalty\": 1.1,\n",
    "                    \"num_predict\": 300\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Limpiar y parsear respuesta\n",
    "            content = respuesta['message']['content'].strip()\n",
    "            return self._parse_json_response(content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error procesando con Ollama: {str(e)}\"}\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Limpia el texto extraído del PDF\"\"\"\n",
    "        # Eliminar saltos de línea excesivos\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        # Eliminar espacios excesivos\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        # Eliminar caracteres especiales problemáticos\n",
    "        text = re.sub(r'[^\\w\\s\\.,:/\\-()$]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def _parse_json_response(self, content: str) -> Dict:\n",
    "        \"\"\"Parsea la respuesta JSON del modelo\"\"\"\n",
    "        try:\n",
    "            # Buscar JSON en la respuesta\n",
    "            json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                resultado = json.loads(json_str)\n",
    "                \n",
    "                # Validar campos requeridos\n",
    "                campos_req = ['banco', 'tasa_fwd', 'valor_nominal_usd', 'fecha_inicio']\n",
    "                if all(campo in resultado for campo in campos_req):\n",
    "                    return resultado\n",
    "                else:\n",
    "                    return {\"error\": \"Campos faltantes in JSON\", \"data\": resultado}\n",
    "            else:\n",
    "                return {\"error\": \"No se encontró JSON válido\", \"raw_response\": content}\n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\"error\": f\"Error parseando JSON: {str(e)}\", \"raw_response\": content}\n",
    "    \n",
    "    def process_multiple_pdfs(self, pdf_directory: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Procesa múltiples PDFs en un directorio\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        pdf_dir = Path(pdf_directory)\n",
    "        \n",
    "        if not pdf_dir.exists():\n",
    "            return {\"error\": f\"Directorio no encontrado: {pdf_directory}\"}\n",
    "        \n",
    "        pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            print(f\"Procesando: {pdf_file.name}\")\n",
    "            results[pdf_file.name] = self.extract_contract_data(str(pdf_file))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Función principal para uso directo\n",
    "def extraer_de_pdf(pdf_path: str, model=\"llama3.2:3b\") -> Dict:\n",
    "    \"\"\"\n",
    "    Función simple para extraer datos de un PDF\n",
    "    \"\"\"\n",
    "    extractor = ContractExtractor(model=model)\n",
    "    return extractor.extract_contract_data(pdf_path)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Tu archivo específico\n",
    "    #pdf_path = r\"Z:\\11_Gersi\\Contratos Firmados\\CITI\\Citi 26 Nov 19915 Firmado.pdf\"\n",
    "    pdf_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\BANCO SANTANDER 17-06-25 1009.pdf\"\n",
    "    \n",
    "    # Extraer datos\n",
    "    resultado = extraer_de_pdf(pdf_path)\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    print(json.dumps(resultado, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # Ejemplo para procesar múltiples PDFs\n",
    "    # extractor = ContractExtractor()\n",
    "    # resultados = extractor.process_multiple_pdfs(r\"Z:\\11_Gersi\\Contratos Firmados\\CITI\")\n",
    "    # print(json.dumps(resultados, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17091b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracción completada. Resultados guardados en: Z:\\17. Reporting Automation\\Cartas NDFs\\forward_tracking_20250730.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import ollama\n",
    "\n",
    "# Configurar Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# Fecha actual\n",
    "today = datetime.now()\n",
    "year = today.strftime(\"%Y\")\n",
    "month = today.strftime(\"%m\")\n",
    "day = today.strftime(\"%d%m%y\")\n",
    "fecha_proceso = today.strftime('%d-%m-%y')\n",
    "\n",
    "# Directorios\n",
    "input_dir = Path(r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas sin firmas\") / year / month / day\n",
    "output_base_dir = Path(r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas para firmar\")\n",
    "excel_output_dir = Path(r\"Z:/17. Reporting Automation/Cartas NDFs\")\n",
    "excel_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Patrones para extraer el banco\n",
    "banco_patterns = [\n",
    "    r\"JPMorgan, N\\.A\\.\",\n",
    "    r\"(SCOTIABANK)\",\n",
    "    r\"(DAVIVIENDA)\",\n",
    "    r\"(ITAÚ)\",\n",
    "    r\"(BANCOLOMBIA)\",\n",
    "    r\"(JPMorgan)\",\n",
    "    r\"(BANCO DE OCCIDENTE)\",\n",
    "    r\"(BANCO SANTANDER)\",\n",
    "    r\"(CITIBANK COLOMBIA)\"\n",
    "]\n",
    "\n",
    "# Función para extraer el nombre del banco usando OCR\n",
    "def extract_banco_from_pdf(pdf_path):\n",
    "    try:\n",
    "        images = convert_from_path(\n",
    "            pdf_path,\n",
    "            dpi=500,\n",
    "            poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin'\n",
    "        )\n",
    "        text = \"\"\n",
    "        for image in images:\n",
    "            text += pytesseract.image_to_string(image, lang='spa')\n",
    "        for pattern in banco_patterns:\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip().upper()\n",
    "        return \"BANCO_DESCONOCIDO\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error extrayendo banco de {pdf_path}: {e}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "# Clase para extracción con LLM\n",
    "class ContractExtractor:\n",
    "    def __init__(self, model=\"llama3.2:3b\"):\n",
    "        self.model = model\n",
    "\n",
    "    def extract_contract_data(self, pdf_path: str) -> dict:\n",
    "        try:\n",
    "            images = convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=500,\n",
    "                poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin'\n",
    "            )\n",
    "            text = \"\"\n",
    "            for image in images:\n",
    "                text += pytesseract.image_to_string(image, lang='spa+eng')\n",
    "\n",
    "            texto_limpio = re.sub(r'\\n+', '\\n', text)\n",
    "            texto_limpio = re.sub(r' +', ' ', texto_limpio)\n",
    "            texto_limpio = re.sub(r'[^\\w\\s\\.,:/\\-()$áéíóúüñÁÉÍÓÚÜÑ]', '', texto_limpio).strip()\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "Eres un asistente especializado en análisis de contratos financieros.\n",
    "\n",
    "Extrae ÚNICAMENTE estos campos del texto del contrato y responde con JSON limpio:\n",
    "\n",
    "- tasa_fwd: Tasa Forward SIN PUNTOS DE MILES (formato: 4236,20 NO 4.236,20)\n",
    "- valor_nominal_usd: Monto en USD (solo números, sin puntos ni comas)\n",
    "- fecha_inicio: Fecha de operación/negociación (formato dd/mm/aaaa)\n",
    "\n",
    "IMPORTANTE: \n",
    "- Para tasa_fwd: Si ves 4.236,20 debe ser 4236,20\n",
    "- Para valor_nominal_usd: Si ves 2,000,000 debe ser 2000000\n",
    "- Responde SOLO con el JSON, sin explicaciones adicionales.\n",
    "\n",
    "Texto del contrato:\n",
    "{texto_limpio[:3000]}\n",
    "\"\"\"\n",
    "            respuesta = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"repeat_penalty\": 1.1,\n",
    "                    \"num_predict\": 300\n",
    "                }\n",
    "            )\n",
    "            content = respuesta['message']['content'].strip()\n",
    "            json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            else:\n",
    "                return {\"error\": \"No se encontró JSON válido\", \"raw_response\": content}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error procesando con Ollama: {str(e)}\"}\n",
    "\n",
    "# Procesamiento de PDFs\n",
    "records = []\n",
    "current_id = 1001\n",
    "extractor = ContractExtractor()\n",
    "\n",
    "for pdf_file in input_dir.glob(\"*.pdf\"):\n",
    "    banco = extract_banco_from_pdf(str(pdf_file))\n",
    "    resultado_llm = extractor.extract_contract_data(str(pdf_file))\n",
    "\n",
    "    nuevo_nombre = f\"{banco} {fecha_proceso} {current_id}.pdf\"\n",
    "    destino_dir = output_base_dir / year / month / day / banco\n",
    "    destino_dir.mkdir(parents=True, exist_ok=True)\n",
    "    nuevo_path = destino_dir / nuevo_nombre\n",
    "\n",
    "    try:\n",
    "        shutil.move(str(pdf_file), str(nuevo_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error moviendo archivo {pdf_file.name}: {e}\")\n",
    "\n",
    "    record = {\n",
    "        \"id\": current_id,\n",
    "        \"archivo_original\": pdf_file.name,\n",
    "        \"nuevo_nombre_archivo\": nuevo_nombre,\n",
    "        \"banco\": banco,\n",
    "        \"fecha_proceso\": fecha_proceso\n",
    "    }\n",
    "\n",
    "    if 'error' in resultado_llm:\n",
    "        record.update({\n",
    "            \"tasa_fwd\": \"ERROR\",\n",
    "            \"valor_nominal_usd\": \"ERROR\",\n",
    "            \"fecha_inicio\": \"ERROR\",\n",
    "            \"error\": resultado_llm.get(\"error\", \"Error desconocido\")\n",
    "        })\n",
    "    else:\n",
    "        record.update({\n",
    "            \"tasa_fwd\": resultado_llm.get(\"tasa_fwd\", \"\"),\n",
    "            \"valor_nominal_usd\": resultado_llm.get(\"valor_nominal_usd\", \"\"),\n",
    "            \"fecha_inicio\": resultado_llm.get(\"fecha_inicio\", \"\"),\n",
    "            \"error\": \"\"\n",
    "        })\n",
    "\n",
    "    records.append(record)\n",
    "    current_id += 1\n",
    "\n",
    "# Guardar resultados en Excel\n",
    "df = pd.DataFrame(records)\n",
    "timestamp = datetime.now().strftime('%Y%m%d')\n",
    "excel_path = excel_output_dir / f\"forward_tracking_{timestamp}.xlsx\"\n",
    "df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Extracción completada. Resultados guardados en: {excel_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "from typing import Dict, Optional\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class ContractExtractor:\n",
    "    def __init__(self, model=\"llama3.2:3b\"):\n",
    "        self.model = model\n",
    "        # Configurar Tesseract (ajustar path según tu instalación)\n",
    "        pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: str, method=\"auto\") -> str:\n",
    "        \"\"\"\n",
    "        Extrae texto de PDF usando diferentes métodos incluyendo OCR\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if method == \"auto\":\n",
    "                # Primero intentar extracción normal\n",
    "                text = self._extract_with_pdfplumber(pdf_path)\n",
    "                \n",
    "                # Si no hay texto o es muy poco, usar OCR\n",
    "                if not text or len(text.strip()) < 100:\n",
    "                    print(\"PDF parece escaneado, usando OCR...\")\n",
    "                    text = self._extract_with_ocr(pdf_path)\n",
    "                \n",
    "                return text\n",
    "            \n",
    "            elif method == \"pdfplumber\":\n",
    "                return self._extract_with_pdfplumber(pdf_path)\n",
    "            elif method == \"pymupdf\":\n",
    "                return self._extract_with_pymupdf(pdf_path)\n",
    "            elif method == \"ocr\":\n",
    "                return self._extract_with_ocr(pdf_path)\n",
    "            else:\n",
    "                raise ValueError(\"Método no soportado\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extrayendo texto: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _extract_with_pdfplumber(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extrae texto usando pdfplumber (mejor para tablas)\"\"\"\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "        return text\n",
    "    \n",
    "    def _extract_with_pymupdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extrae texto usando PyMuPDF (más rápido)\"\"\"\n",
    "        text = \"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc[page_num]\n",
    "            text += page.get_text() + \"\\n\"\n",
    "        doc.close()\n",
    "        return text\n",
    "    \n",
    "    def _extract_with_ocr(self, pdf_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Extrae texto usando OCR (para PDFs escaneados)\n",
    "        \"\"\"\n",
    "        text = \"\"\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            \n",
    "            for page_num in range(doc.page_count):\n",
    "                page = doc[page_num]\n",
    "                \n",
    "                # Convertir página a imagen\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Aumentar resolución\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "                \n",
    "                # Convertir a PIL Image\n",
    "                image = Image.open(io.BytesIO(img_data))\n",
    "                \n",
    "                # Aplicar OCR\n",
    "                page_text = pytesseract.image_to_string(image, lang='spa+eng')\n",
    "                text += page_text + \"\\n\"\n",
    "                \n",
    "                print(f\"Página {page_num + 1} procesada con OCR\")\n",
    "            \n",
    "            doc.close()\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en OCR: {e}\")\n",
    "            print(\"Asegúrate de tener instalado Tesseract-OCR\")\n",
    "            return \"\"\n",
    "    \n",
    "    def extract_contract_data(self, pdf_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Extrae datos del contrato desde PDF\n",
    "        \"\"\"\n",
    "        # Verificar si el archivo existe\n",
    "        if not Path(pdf_path).exists():\n",
    "            return {\"error\": f\"Archivo no encontrado: {pdf_path}\"}\n",
    "        \n",
    "        # Extraer texto del PDF (automáticamente detecta si necesita OCR)\n",
    "        print(\"Extrayendo texto del PDF...\")\n",
    "        texto_contrato = self.extract_text_from_pdf(pdf_path, method=\"auto\")\n",
    "        \n",
    "        if not texto_contrato:\n",
    "            return {\"error\": \"No se pudo extraer texto del PDF\"}\n",
    "        \n",
    "        # Limpiar texto\n",
    "        texto_limpio = self._clean_text(texto_contrato)\n",
    "        \n",
    "        # Crear prompt optimizado\n",
    "        prompt = f\"\"\"\n",
    "Eres un asistente especializado en análisis de contratos financieros.\n",
    "\n",
    "Extrae ÚNICAMENTE estos campos del texto del contrato y responde con JSON limpio:\n",
    "\n",
    "- banco: Nombre completo del banco (buscar en encabezados, firmas, \"El Banco\")\n",
    "- tasa_fwd: Tasa Forward SIN PUNTOS DE MILES (formato: 4236,20 NO 4.236,20)\n",
    "- valor_nominal_usd: Monto en USD (solo números, sin puntos ni comas)\n",
    "- fecha_inicio: Fecha de operación/negociación (formato dd/mm/aaaa)\n",
    "\n",
    "IMPORTANTE: \n",
    "- Para tasa_fwd: Si ves 4.236,20 debe ser 4236,20\n",
    "- Para valor_nominal_usd: Si ves 2,000,000 debe ser 2000000\n",
    "- Responde SOLO con el JSON, sin explicaciones adicionales.\n",
    "\n",
    "Texto del contrato:\n",
    "{texto_limpio[:3000]}\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(\"Procesando con Ollama...\")\n",
    "            respuesta = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"repeat_penalty\": 1.1,\n",
    "                    \"num_predict\": 300\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Limpiar y parsear respuesta\n",
    "            content = respuesta['message']['content'].strip()\n",
    "            resultado = self._parse_json_response(content)\n",
    "            \n",
    "            # Aplicar limpieza adicional\n",
    "            if isinstance(resultado, dict) and 'error' not in resultado:\n",
    "                resultado = self._clean_extracted_data(resultado)\n",
    "            \n",
    "            return resultado\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error procesando con Ollama: {str(e)}\"}\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Limpia el texto extraído del PDF\"\"\"\n",
    "        # Eliminar saltos de línea excesivos\n",
    "        text = re.sub(r'\\n+', '\\n', text)\n",
    "        # Eliminar espacios excesivos\n",
    "        text = re.sub(r' +', ' ', text)\n",
    "        # Eliminar caracteres especiales problemáticos pero mantener los importantes\n",
    "        text = re.sub(r'[^\\w\\s\\.,:/\\-()$áéíóúüñÁÉÍÓÚÜÑ]', '', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def _clean_extracted_data(self, data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Limpia y formatea los datos extraídos\n",
    "        \"\"\"\n",
    "        # Limpiar tasa forward - ELIMINAR PUNTOS DE MILES\n",
    "        if data.get('tasa_fwd'):\n",
    "            tasa = str(data['tasa_fwd'])\n",
    "            # Eliminar puntos de miles, mantener solo coma decimal\n",
    "            tasa = re.sub(r'\\.(?=\\d{3})', '', tasa)  # Eliminar puntos de miles\n",
    "            tasa = tasa.replace('.', ',')  # Convertir punto decimal a coma\n",
    "            data['tasa_fwd'] = tasa\n",
    "        \n",
    "        # Limpiar valor nominal - eliminar puntos y comas\n",
    "        if data.get('valor_nominal_usd'):\n",
    "            valor = str(data['valor_nominal_usd'])\n",
    "            valor = re.sub(r'[.,]', '', valor)  # Eliminar todos los puntos y comas\n",
    "            data['valor_nominal_usd'] = valor\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def _parse_json_response(self, content: str) -> Dict:\n",
    "        \"\"\"Parsea la respuesta JSON del modelo\"\"\"\n",
    "        try:\n",
    "            # Buscar JSON en la respuesta\n",
    "            json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                resultado = json.loads(json_str)\n",
    "                \n",
    "                # Validar campos requeridos\n",
    "                campos_req = ['banco', 'tasa_fwd', 'valor_nominal_usd', 'fecha_inicio']\n",
    "                if all(campo in resultado for campo in campos_req):\n",
    "                    return resultado\n",
    "                else:\n",
    "                    return {\"error\": \"Campos faltantes en JSON\", \"data\": resultado}\n",
    "            else:\n",
    "                return {\"error\": \"No se encontró JSON válido\", \"raw_response\": content}\n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\"error\": f\"Error parseando JSON: {str(e)}\", \"raw_response\": content}\n",
    "    \n",
    "    def save_to_excel(self, resultado: Dict, pdf_filename: str, output_dir: str = r\"Z:\\17. Reporting Automation\\Cartas NDFs\") -> str:\n",
    "        \"\"\"\n",
    "        Guarda el resultado en Excel\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Crear directorio si no existe\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Preparar datos para Excel\n",
    "            if 'error' in resultado:\n",
    "                # Si hay error, guardar información del error\n",
    "                excel_data = {\n",
    "                    'archivo': [pdf_filename],\n",
    "                    'banco': ['ERROR'],\n",
    "                    'tasa_fwd': ['ERROR'],\n",
    "                    'valor_nominal_usd': ['ERROR'],\n",
    "                    'fecha_inicio': ['ERROR'],\n",
    "                    'error': [resultado.get('error', 'Error desconocido')],\n",
    "                    'fecha_procesamiento': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')]\n",
    "                }\n",
    "            else:\n",
    "                # Datos normales\n",
    "                excel_data = {\n",
    "                    'archivo': [pdf_filename],\n",
    "                    'banco': [resultado.get('banco', '')],\n",
    "                    'tasa_fwd': [resultado.get('tasa_fwd', '')],\n",
    "                    'valor_nominal_usd': [resultado.get('valor_nominal_usd', '')],\n",
    "                    'fecha_inicio': [resultado.get('fecha_inicio', '')],\n",
    "                    'error': [''],\n",
    "                    'fecha_procesamiento': [datetime.now().strftime('%Y-%m-%d %H:%M:%S')]\n",
    "                }\n",
    "            \n",
    "            # Crear DataFrame\n",
    "            df = pd.DataFrame(excel_data)\n",
    "            \n",
    "            # Nombre del archivo Excel\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            excel_filename = f\"contrato_extraido_{timestamp}.xlsx\"\n",
    "            excel_path = Path(output_dir) / excel_filename\n",
    "            \n",
    "            # Guardar en Excel\n",
    "            df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "            \n",
    "            print(f\"Resultado guardado en: {excel_path}\")\n",
    "            return str(excel_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error guardando en Excel: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def save_multiple_to_excel(self, resultados: Dict, output_dir: str = r\"Z:\\17. Reporting Automation\\Cartas NDFs\") -> str:\n",
    "        \"\"\"\n",
    "        Guarda múltiples resultados en un solo archivo Excel\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Crear directorio si no existe\n",
    "            Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Preparar datos para Excel\n",
    "            excel_data = {\n",
    "                'archivo': [],\n",
    "                'banco': [],\n",
    "                'tasa_fwd': [],\n",
    "                'valor_nominal_usd': [],\n",
    "                'fecha_inicio': [],\n",
    "                'error': [],\n",
    "                'fecha_procesamiento': []\n",
    "            }\n",
    "            \n",
    "            for filename, resultado in resultados.items():\n",
    "                excel_data['archivo'].append(filename)\n",
    "                excel_data['fecha_procesamiento'].append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "                \n",
    "                if 'error' in resultado:\n",
    "                    excel_data['banco'].append('ERROR')\n",
    "                    excel_data['tasa_fwd'].append('ERROR')\n",
    "                    excel_data['valor_nominal_usd'].append('ERROR')\n",
    "                    excel_data['fecha_inicio'].append('ERROR')\n",
    "                    excel_data['error'].append(resultado.get('error', 'Error desconocido'))\n",
    "                else:\n",
    "                    excel_data['banco'].append(resultado.get('banco', ''))\n",
    "                    excel_data['tasa_fwd'].append(resultado.get('tasa_fwd', ''))\n",
    "                    excel_data['valor_nominal_usd'].append(resultado.get('valor_nominal_usd', ''))\n",
    "                    excel_data['fecha_inicio'].append(resultado.get('fecha_inicio', ''))\n",
    "                    excel_data['error'].append('')\n",
    "            \n",
    "            # Crear DataFrame\n",
    "            df = pd.DataFrame(excel_data)\n",
    "            \n",
    "            # Nombre del archivo Excel\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            excel_filename = f\"contratos_extraidos_{timestamp}.xlsx\"\n",
    "            excel_path = Path(output_dir) / excel_filename\n",
    "            \n",
    "            # Guardar en Excel\n",
    "            df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "            \n",
    "            print(f\"Resultados guardados en: {excel_path}\")\n",
    "            return str(excel_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error guardando múltiples resultados en Excel: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return error_msg\n",
    "    \n",
    "    def process_multiple_pdfs(self, pdf_directory: str, save_excel: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Procesa múltiples PDFs en un directorio y opcionalmente guarda en Excel\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        pdf_dir = Path(pdf_directory)\n",
    "        \n",
    "        if not pdf_dir.exists():\n",
    "            return {\"error\": f\"Directorio no encontrado: {pdf_directory}\"}\n",
    "        \n",
    "        pdf_files = list(pdf_dir.glob(\"*.pdf\"))\n",
    "        \n",
    "        for pdf_file in pdf_files:\n",
    "            print(f\"Procesando: {pdf_file.name}\")\n",
    "            results[pdf_file.name] = self.extract_contract_data(str(pdf_file))\n",
    "        \n",
    "        # Guardar en Excel si se solicita\n",
    "        if save_excel and results:\n",
    "            excel_path = self.save_multiple_to_excel(results)\n",
    "            results['_excel_path'] = excel_path\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Funciones de conveniencia\n",
    "def extraer_de_pdf(pdf_path: str, model=\"llama3.2:3b\", save_excel: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Función simple para extraer datos de un PDF y guardarlo en Excel\n",
    "    \"\"\"\n",
    "    extractor = ContractExtractor(model=model)\n",
    "    resultado = extractor.extract_contract_data(pdf_path)\n",
    "    \n",
    "    if save_excel:\n",
    "        pdf_filename = Path(pdf_path).name\n",
    "        excel_path = extractor.save_to_excel(resultado, pdf_filename)\n",
    "        resultado['_excel_path'] = excel_path\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "def procesar_directorio(directorio: str, model=\"llama3.2:3b\") -> Dict:\n",
    "    \"\"\"\n",
    "    Procesa todos los PDFs de un directorio y guarda en Excel\n",
    "    \"\"\"\n",
    "    extractor = ContractExtractor(model=model)\n",
    "    return extractor.process_multiple_pdfs(directorio, save_excel=True)\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Procesar un PDF individual\n",
    "    #pdf_path = r\"Z:\\11_Gersi\\Contratos Firmados\\CITI\\Citi 26 Nov 19915 Firmado.pdf\"\n",
    "    pdf_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\BANCO SANTANDER 17-06-25 1009.pdf\"\n",
    "    resultado = extraer_de_pdf(pdf_path, save_excel=True)\n",
    "    \n",
    "    print(\"Resultado:\")\n",
    "    print(json.dumps(resultado, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # Procesar directorio completo\n",
    "    # resultados = procesar_directorio(r\"Z:\\11_Gersi\\Contratos Firmados\\CITI\")\n",
    "    # print(\"Todos los contratos procesados y guardados en Excel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9780e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path \n",
    "\n",
    "# Configurar la ruta de Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\ntorreslo\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "tasa_patterns = [\n",
    "                   r\"Forward Rate:\\s*([\\d.,]+)\"\n",
    "                 , r\"Tasa Forward\\s*[-:]?\\s*([\\d.,]+)\"\n",
    "                 , r\"Tasa Forward\\s*[-:]?\\s*([\\d.,]+)\"\n",
    "                 , r\"(?i)(Tasa Forward|Forward Rate|Tasa):?\\s*\\$?\\s*([\\d\\.,]+)\"\n",
    "                 , r'(?:Tasa Forward|Forward Rate|Tasa FW).*?[:\\s].*?[\\$\\s]*([\\d,]+\\.?\\d*)'\n",
    "                 , r'(\\d{4}[\\.,]\\d{2})\\s*COP/USD'\n",
    "                 , r'[\\|\\s](\\d{4}[\\.,]\\d{2})[\\|\\s]'\n",
    "                 , r'(\\b\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})\\b)'\n",
    "                 ]\n",
    "\n",
    "valor_patterns = [\n",
    "    r\"(?:Valor(?: Nocional| Nominal)?|Notional Amount|Monto en USD|Valor Negociado).*?:?\\s*USD\\s*([\\d.,]+)\",\n",
    "    r\"USD\\s*([\\d.,]+)\",\n",
    "    r\"(?:nocional|nominal|monto|valor)\\s*[:\\-]?\\s*\\$?\\s?\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})?\"\n",
    "]\n",
    "\n",
    "fecha_patterns = [\n",
    "    r\"(?:Fecha(?: de Celebraci[oó]n| de Vencimiento| de celebración)?|Trade Date).*?[:\\-]?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4})\",\n",
    "    r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\",\n",
    "    r\"\\b\\d{1,2}\\s+de\\s+\\w{3,9}\\.?(\\s+de)?\\s+\\d{4}\\b\"\n",
    "]\n",
    "\n",
    "banco_patterns = [\n",
    "                    r\"JPMorgan, N\\.A\\.\"\n",
    "                  , r\"SCOTIABANK\\.A\\.\"\n",
    "                  , r'(SCOTIABANK COLPATRIA S\\.A\\.)'\n",
    "                  , r'(DAVIVIENDA)'\n",
    "                  , r'(ITAÚ COLOMBIA S\\.A\\.)'\n",
    "                  , r'(BANCOLOMBIA S\\.A\\.)'\n",
    "                  , r'(JPMorgan)'\n",
    "                  , r'(BANCO DE OCCIDENTE)'\n",
    "                  , r'(BANCO SANTANDER[^,]*)'\n",
    "                  , r'(CITIBANK COLOMBIA)'\n",
    "                  \n",
    "                  ]\n",
    "\n",
    "def extract_data_from_pdf(file_path):\n",
    "    images = convert_from_path(file_path\n",
    "                               , dpi = 500\n",
    "                               , poppler_path=r'C:\\Poppler\\poppler-24.08.0\\Library\\bin')  \n",
    "    text = \"\"\n",
    "    for image in images:\n",
    "        text += pytesseract.image_to_string(image, lang='spa')  # Cambia 'spa' por el idioma deseado\n",
    "\n",
    "    # Define regex patterns for both Spanish and English documents\n",
    "    patterns = {\n",
    "        \"fecha_celebracion\": fecha_patterns[0],\n",
    "        \"tasa_forward\": tasa_patterns[0],\n",
    "        \"valor_nominal\": valor_patterns[0],\n",
    "        \"contraparte\": banco_patterns[0]\n",
    "        \n",
    "    }\n",
    "      \n",
    "\n",
    "    data = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            data[key] = match.group(2).strip() if match.lastindex >= 2 else match.group(1).strip()\n",
    "        else:\n",
    "            data[key] = None\n",
    "\n",
    "    # Clean the forward rate to retain only digits, commas, and periods\n",
    "    if data[\"tasa_forward\"]:\n",
    "        data[\"tasa_forward\"] = re.sub(r\"[^\\d,\\.]\", \"\", data[\"tasa_forward\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_pdfs_in_directory(directory):\n",
    "    records = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            data = extract_data_from_pdf(file_path)\n",
    "            data[\"nombre_archivo\"] = filename\n",
    "            records.append(data)\n",
    "    return records\n",
    "\n",
    "# Directory containing the PDFs\n",
    "directory = r\"Z:/17. Reporting Automation/Cartas NDFs/Cartas sin firmas\"\n",
    "output_file = r\"Z:/17. Reporting Automation/Cartas NDFs/forward_tracking_2.xlsx\"\n",
    "\n",
    "# Process the PDFs and get the data\n",
    "records = process_pdfs_in_directory(directory)\n",
    "\n",
    "# Create a DataFrame and save to Excel\n",
    "df = pd.DataFrame(records)\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"The data has been successfully extracted and saved to forward_tracking.xlsx.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4471edc7",
   "metadata": {},
   "source": [
    "4. Cambiar el nombres por el que ya se tiene con los bancos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad127f",
   "metadata": {},
   "source": [
    "5. Enviar al gerente respectivo a firmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cae71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import win32com.client as win32\n",
    "from datetime import datetime\n",
    "\n",
    "# Ruta de los archivos PDF\n",
    "pdf_folder = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\Cartas para firmar\"\n",
    "\n",
    "# Obtener la fecha actual en formato dd-mm-aa\n",
    "fecha_hoy = datetime.now().strftime(\"%d-%m-%y\")\n",
    "\n",
    "# Crear instancia de Outlook\n",
    "olApp = win32.Dispatch('Outlook.Application')\n",
    "olNS = olApp.GetNameSpace('MAPI')\n",
    "\n",
    "# Crear el correo\n",
    "mailItem = olApp.CreateItem(0)\n",
    "mailItem.Subject = f'Cartas NDFs {fecha_hoy}'\n",
    "mailItem.BodyFormat = 1\n",
    "mailItem.Body = \"\"\"Cordial saludo, \n",
    "\n",
    "Adjunto confirmaciones para su firma. Mil gracias.\n",
    "\n",
    "Saludos,\n",
    "NTL\n",
    "\n",
    "\"\"\"\n",
    "mailItem.To = 'johann.najar@telefonica.com'\n",
    "#mailItem.To = 'n.torres01@telefonica.com'\n",
    "\n",
    "# Adjuntar todos los archivos PDF de la carpeta\n",
    "for file in os.listdir(pdf_folder):\n",
    "    if file.lower().endswith(\".pdf\"):\n",
    "        full_path = os.path.join(pdf_folder, file)\n",
    "        mailItem.Attachments.Add(full_path)\n",
    "\n",
    "# Mostrar, guardar y enviar\n",
    "mailItem.Display()\n",
    "mailItem.Save()\n",
    "mailItem.Send()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c669c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Inicializar la aplicación de Outlook\n",
    "    outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "    inbox = outlook.Folders(\"n.torres01@telefonica.com\").Folders(\"Inbox\").Folders(\"Spot\")\n",
    "\n",
    "    # Obtener todos los mensajes\n",
    "    messages = inbox.Items\n",
    "    messages.Sort(\"[ReceivedTime]\", True)  # Ordenar por fecha descendente\n",
    "\n",
    "    # Buscar el primer mensaje del remitente deseado\n",
    "    latest_message = None\n",
    "    for message in messages:\n",
    "        if message.Class == 43:  # Asegura que sea un MailItem\n",
    "            sender = message.SenderEmailAddress.lower()\n",
    "            if \"johann.najar@telefonica.com\" in sender:\n",
    "                latest_message = message\n",
    "                break\n",
    "\n",
    "    if latest_message:\n",
    "        # Obtener el contenido del mensaje\n",
    "        message_content = latest_message.Body\n",
    "\n",
    "        # Ruta del archivo de salida\n",
    "        file_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\latest_email.txt\"\n",
    "\n",
    "        # Escribir el contenido en el archivo\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(message_content)\n",
    "\n",
    "        print(f\"✅ El contenido del último correo de Johann Najar fue guardado en:\\n{file_path}\")\n",
    "    else:\n",
    "        print(\"⚠️ No se encontró ningún correo reciente de johann.najar@telefonica.com en la bandeja de entrada.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ocurrió un error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa697e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "try:\n",
    "    # Inicializar la aplicación de Outlook\n",
    "    outlook = win32com.client.Dispatch(\"Outlook.Application\").GetNamespace(\"MAPI\")\n",
    "    inbox = outlook.Folders(\"n.torres01@telefonica.com\").Folders(\"Inbox\").Folders(\"Spot\")\n",
    "\n",
    "    # Obtener la fecha de hace una semana\n",
    "    last_week = datetime.now() - timedelta(days=7)\n",
    "\n",
    "    # Obtener todos los mensajes\n",
    "    messages = inbox.Items\n",
    "    messages.Sort(\"[ReceivedTime]\", True)  # Ordenar por fecha descendente\n",
    "\n",
    "    # Buscar el primer mensaje con el asunto deseado de la última semana\n",
    "    latest_message = None\n",
    "    for message in messages:\n",
    "        if message.Class == 43:  # Asegura que sea un MailItem\n",
    "            if 'COMPRA DE DOLARES' in message.Subject.upper() and message.ReceivedTime >= last_week:\n",
    "                latest_message = message\n",
    "                break\n",
    "\n",
    "    if latest_message:\n",
    "        # Obtener el contenido del mensaje\n",
    "        message_content = latest_message.Body\n",
    "\n",
    "        # Ruta del archivo de salida\n",
    "        file_path = r\"Z:\\17. Reporting Automation\\Cartas NDFs\\latest_email.txt\"\n",
    "\n",
    "        # Escribir el contenido en el archivo\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(message_content)\n",
    "\n",
    "        print(f\"✅ El contenido del último correo con asunto 'COMPRA DE DOLARES' fue guardado en:\\n{file_path}\")\n",
    "    else:\n",
    "        print(\"⚠️ No se encontró ningún correo reciente con el asunto 'COMPRA DE DOLARES' en la última semana.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ocurrió un error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
